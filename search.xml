<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>Keras学习之ImageDataGenerator方法</title>
      <link href="/2020/04/27/Keras%E5%AD%A6%E4%B9%A0%E4%B9%8BImageDataGenerator%E6%96%B9%E6%B3%95/"/>
      <url>/2020/04/27/Keras%E5%AD%A6%E4%B9%A0%E4%B9%8BImageDataGenerator%E6%96%B9%E6%B3%95/</url>
      
        <content type="html"><![CDATA[<p><code>ImageDataGenerator</code>是Keras中用于图像预处理的一个方法，当我们的数据集较小时，使用这个方法可以增加我们的数据，因而使训练的结果更加准确。</p><p>这个方法当中的一些参数我一直是很蒙的状态，不知道预设这些参数后对数据产生何种影响。因此想借助官方的中文文档，加深我对这些数据的理解。老规矩，这里附上官方文档的超链接，点击<a href="https://keras.io/zh/preprocessing/image/#imagedatagenerator" target="_blank" rel="noopener">图像预处理ImageDataGenerator</a>查看。</p><h3 id="方法的引入"><a class="markdownIt-Anchor" href="#方法的引入"></a> 方法的引入</h3><p>首先在使用这个方法之前，应该学习如何在代码中引入，方法如下：</p><figure class="highlight elm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> Keras</span><br><span class="line"><span class="title">from</span> keras.processing.image <span class="keyword">import</span> ImageDataGenerator</span><br></pre></td></tr></table></figure><h3 id="参数"><a class="markdownIt-Anchor" href="#参数"></a> 参数</h3><p>在引入<code>ImageDataGenerator</code>方法之后，接下来我们来看一下，其中的方法中的参数：</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">keras.preprocessing.image.ImageDataGenerator(<span class="attribute">featurewise_center</span>=<span class="literal">False</span>,  </span><br><span class="line">                                             <span class="attribute">samplewise_center</span>=<span class="literal">False</span>, </span><br><span class="line">                                             <span class="attribute">featurewise_std_normalization</span>=<span class="literal">False</span>, </span><br><span class="line">                                             <span class="attribute">samplewise_std_normalization</span>=<span class="literal">False</span>, </span><br><span class="line">                                             <span class="attribute">zca_whitening</span>=<span class="literal">False</span>, </span><br><span class="line">                                             <span class="attribute">zca_epsilon</span>=1e-06, </span><br><span class="line">                                             <span class="attribute">rotation_range</span>=0, </span><br><span class="line">                                             <span class="attribute">width_shift_range</span>=0.0, </span><br><span class="line">                                             <span class="attribute">height_shift_range</span>=0.0, </span><br><span class="line">                                             <span class="attribute">brightness_range</span>=None, </span><br><span class="line">                                             <span class="attribute">shear_range</span>=0.0, </span><br><span class="line">                                             <span class="attribute">zoom_range</span>=0.0, </span><br><span class="line">                                             <span class="attribute">channel_shift_range</span>=0.0, </span><br><span class="line">                                             <span class="attribute">fill_mode</span>=<span class="string">'nearest'</span>, </span><br><span class="line">                                             <span class="attribute">cval</span>=0.0, </span><br><span class="line">                                             <span class="attribute">horizontal_flip</span>=<span class="literal">False</span>, </span><br><span class="line">                                             <span class="attribute">vertical_flip</span>=<span class="literal">False</span>, </span><br><span class="line">                                             <span class="attribute">rescale</span>=None, </span><br><span class="line">                                             <span class="attribute">preprocessing_function</span>=None, </span><br><span class="line">                                             <span class="attribute">data_format</span>=None, </span><br><span class="line">                                             <span class="attribute">validation_split</span>=0.0, </span><br><span class="line">                                             <span class="attribute">dtype</span>=None)</span><br></pre></td></tr></table></figure><p>这个方法的参数，说实话真的很多，也侧面说明该方法的强大，下面我们挑几个常用的参数来进行解释，解释这些参数的作用与如何设置。</p><ul><li><p><strong>featurewise_center</strong>: 布尔值。将输入数据的均值设置为 0，逐特征进行。</p></li><li><p><strong>samplewise_center</strong>: 布尔值。将每个样本的均值设置为 0。</p></li><li><p><strong>featurewise_std_normalization</strong>: Boolean. 布尔值。将输入除以数据标准差，逐特征进行。</p></li><li><p><strong>samplewise_std_normalization</strong>: 布尔值。将每个输入除以其标准差。</p></li><li><p><strong>rotation_range</strong>: 整数。随机旋转的度数范围。</p></li><li><p>width_shift_range: 浮点数、一维数组或整数</p><ul><li>float: 如果 &lt;1，则是除以总宽度的值，或者如果 &gt;=1，则为像素值。</li><li>1-D 数组: 数组中的随机元素。</li><li>int: 来自间隔 <code>(-width_shift_range, +width_shift_range)</code> 之间的整数个像素。</li><li><code>width_shift_range=2</code> 时，可能值是整数 <code>[-1, 0, +1]</code>，与 <code>width_shift_range=[-1, 0, +1]</code> 相同；而 <code>width_shift_range=1.0</code> 时，可能值是 <code>[-1.0, +1.0)</code> 之间的浮点数。</li></ul></li><li><p>height_shift_range: 浮点数、一维数组或整数</p><ul><li>float: 如果 &lt;1，则是除以总宽度的值，或者如果 &gt;=1，则为像素值。</li><li>1-D array-like: 数组中的随机元素。</li><li>int: 来自间隔 <code>(-height_shift_range, +height_shift_range)</code> 之间的整数个像素。</li><li><code>height_shift_range=2</code> 时，可能值是整数 <code>[-1, 0, +1]</code>，与 <code>height_shift_range=[-1, 0, +1]</code> 相同；而 <code>height_shift_range=1.0</code> 时，可能值是 <code>[-1.0, +1.0)</code> 之间的浮点数。</li></ul></li><li><p><strong>shear_range</strong>: 浮点数。剪切强度（以弧度<strong>逆时针</strong>方向剪切角度）。</p></li><li><p><strong>zoom_range</strong>: 浮点数 或 <code>[lower, upper]</code>。随机缩放范围。如果是浮点数，<code>[lower, upper] = [1-zoom_range, 1+zoom_range]</code>。</p></li><li><p><strong>horizontal_flip</strong>: 布尔值。随机水平翻转。</p></li><li><p><strong>vertical_flip</strong>: 布尔值。随机垂直翻转。</p></li><li><p><strong>rescale</strong>: 重缩放因子。默认为 None。如果是 None 或 0，不进行缩放，否则将数据乘以所提供的值（在应用任何其他转换之前）。</p></li><li><p><strong>preprocessing_function</strong>: 应用于每个输入的函数。这个函数会在任何其他改变之前运行。这个函数需要一个参数：一张图像（秩为 3 的 Numpy 张量），并且应该输出一个同尺寸的 Numpy 张量。</p></li><li><p><strong>validation_split</strong>: 浮点数。Float. 保留用于验证的图像的比例（严格在0和1之间）。</p></li><li><p><strong>dtype</strong>: 生成数组使用的数据类型。</p></li></ul><h3 id="例子"><a class="markdownIt-Anchor" href="#例子"></a> 例子</h3><p>使用<code>.flow(x, y)</code>的例子：</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">（x_train, y_train), (x_test, y_test) = cifar10.load_data()</span><br><span class="line">y_train = np_utils.to_categorical(y_train, num_classes)</span><br><span class="line">y_test = np_utils.to_categorical(y_test, num_classes)</span><br><span class="line"></span><br><span class="line">datagen = ImageDataGenerator(</span><br><span class="line">    <span class="attribute">featurewise_center</span>=<span class="literal">True</span>,</span><br><span class="line">    <span class="attribute">featurewise_std_normalization</span>=<span class="literal">True</span>,</span><br><span class="line">    <span class="attribute">rotation_range</span>=20,</span><br><span class="line">    <span class="attribute">width_shift_range</span>=0.2,</span><br><span class="line">    <span class="attribute">height_shift_range</span>=0.2,</span><br><span class="line">    <span class="attribute">horizontal_flip</span>=<span class="literal">True</span>)</span><br><span class="line">    </span><br><span class="line"><span class="comment"># 计算特征归一化所需的数量</span></span><br><span class="line"><span class="comment"># （如果应用 ZCA 白化，将计算标准差，均值，主成分）</span></span><br><span class="line">datagen.fit(x_train)</span><br><span class="line"></span><br><span class="line"><span class="comment">## 使用实时数据增益的批数据对模型进行拟合：</span></span><br><span class="line">model.fit_generator(datagen.flow(x_train, y_train, <span class="attribute">batch_size</span>=32),steps_per_epoch=len(x_train) / 32, <span class="attribute">epochs</span>=epochs)</span><br></pre></td></tr></table></figure><h3 id="flow"><a class="markdownIt-Anchor" href="#flow"></a> flow</h3><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">flow(x, <span class="attribute">y</span>=None, <span class="attribute">batch_size</span>=32, <span class="attribute">shuffle</span>=<span class="literal">True</span>, <span class="attribute">sample_weight</span>=None, <span class="attribute">seed</span>=None, <span class="attribute">save_to_dir</span>=None, <span class="attribute">save_format</span>=<span class="string">'png'</span>, <span class="attribute">subset</span>=None)</span><br></pre></td></tr></table></figure><p>采集数据和标签数组，生成批量增强数据。</p><p><strong>参数</strong>：</p><ul><li><strong>x</strong>: 输入数据。秩为 4 的 Numpy 矩阵或元组。如果是元组，第一个元素应该包含图像，第二个元素是另一个 Numpy 数组或一列 Numpy 数组，它们不经过任何修改就传递给输出。可用于将模型杂项数据与图像一起输入。对于灰度数据，图像数组的通道轴的值应该为 1，而对于 RGB 数据，其值应该为 3。</li><li><strong>y</strong>: 标签。</li><li><strong>batch_size</strong>: 整数 (默认为 32)。</li><li><strong>shuffle</strong>: 布尔值 (默认为 True)。</li><li><strong>sample_weight</strong>: 样本权重。</li><li><strong>seed</strong>: 整数（默认为 None）。</li><li><strong>save_to_dir</strong>: None 或 字符串（默认为 None）。这使您可以选择指定要保存的正在生成的增强图片的目录（用于可视化您正在执行的操作）。</li><li><strong>save_prefix</strong>: 字符串（默认 <code>''</code>）。保存图片的文件名前缀（仅当 <code>save_to_dir</code> 设置时可用）。</li><li><strong>save_format</strong>: “png”, “jpeg” 之一（仅当 <code>save_to_dir</code> 设置时可用）。默认：“png”。</li><li><strong>subset</strong>: 数据子集 (“training” 或 “validation”)，如果 在 <code>ImageDataGenerator</code> 中设置了 <code>validation_split</code>。</li></ul><p><strong>返回</strong></p><p>一个生成元组 <code>(x, y)</code> 的 <code>Iterator</code>，其中 <code>x</code> 是图像数据的 Numpy 数组（在单张图像输入时），或 Numpy 数组列表（在额外多个输入时），<code>y</code> 是对应的标签的 Numpy 数组。如果 ‘sample_weight’ 不是 None，生成的元组形式为 <code>(x, y, sample_weight)</code>。如果 <code>y</code> 是 None, 只有 Numpy 数组 <code>x</code> 被返回。</p><hr /><p><code>ImageDataGenerator</code>方法功能很强大，这里就列出几个比较常用的，如果在实际应用中有包含没涉及到的，可以直接查看<a href="https://keras.io/zh/preprocessing/image/#imagedatagenerator" target="_blank" rel="noopener">官方文档</a>。</p><p>这里再附上一个CSDN上一位博主写的更加直观的解释，方便加深印象，附上<a href="https://blog.csdn.net/xijuezhu8128/article/details/79895856" target="_blank" rel="noopener">链接</a>可以直接点击查看。</p>]]></content>
      
      
      <categories>
          
          <category> 深度学习小技巧 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Keras </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Keras学习之Model方法</title>
      <link href="/2020/04/27/Keras%E5%AD%A6%E4%B9%A0%E4%B9%8BModel%E6%96%B9%E6%B3%95/"/>
      <url>/2020/04/27/Keras%E5%AD%A6%E4%B9%A0%E4%B9%8BModel%E6%96%B9%E6%B3%95/</url>
      
        <content type="html"><![CDATA[<p>在学习深度学习的时候，Keras逐渐成了我最喜欢使用的深度学习框架，因为用它搭建模型很方面，而且相比较Tensorflow来说要容易很多。</p><p>因为也是一个初学者，经常会遇到很多不会的方法，所以难免需要查询官方文档进行学习。学习任何东西都是一个从陌生到熟悉的过程，因此想在博客里新开一个tag，专门放置一些我刚遇到的还不太会使用的方法，也方便以后学习。</p><p>今天这篇博客的话，主要是学习Keras中Model这个方法的使用，文中的例子来自Keras的<a href="https://keras-cn.readthedocs.io/en/latest/legacy/models/model/#model" target="_blank" rel="noopener">官方文档</a>，如果感兴趣的话，可以直接点击蓝色的超链接进行学习。</p><h3 id="keras的泛型模型接口"><a class="markdownIt-Anchor" href="#keras的泛型模型接口"></a> Keras的泛型模型接口</h3><p>Keras的泛型模型<code>Model</code>, 即广义的拥有输入和输出的模型，我们使用Model来初始化一个泛型模型：</p><figure class="highlight nix"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">from keras.models <span class="built_in">import</span> Model</span><br><span class="line">from keras.layers <span class="built_in">import</span> Input, Dense</span><br><span class="line"></span><br><span class="line"><span class="attr">a</span> = Input(<span class="attr">shape=(32,</span> ))</span><br><span class="line"><span class="attr">b</span> = Dense(<span class="number">32</span>)(a)</span><br><span class="line"><span class="attr">model</span> = Model(<span class="attr">input=a,</span> <span class="attr">output=b)</span></span><br></pre></td></tr></table></figure><p>在这里，我们的模型以<code>a</code>为输入，以<code>b</code>为输出，同样我们可以构造拥有多输入和多输出的模型：</p><figure class="highlight reasonml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model = <span class="constructor">Model(<span class="params">input</span>=[<span class="params">a1</span>, <span class="params">a2</span>], <span class="params">output</span>=[<span class="params">b1</span>, <span class="params">b2</span>, <span class="params">b3</span>])</span></span><br></pre></td></tr></table></figure><h3 id="常用的model属性"><a class="markdownIt-Anchor" href="#常用的model属性"></a> 常用的Model属性</h3><ul><li><code>model.layers</code>：组成模型图的各个层</li><li><code>model.inputs</code>：模型的输入张量列表</li><li><code>model.outputs</code>：模型的输出张量列表</li></ul><h3 id="model模型方法"><a class="markdownIt-Anchor" href="#model模型方法"></a> Model模型方法</h3><p><strong>compile</strong></p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">compile(self, optimizer, loss, metrics=[], <span class="attribute">loss_weights</span>=None, <span class="attribute">sample_weight_model</span>=None)</span><br></pre></td></tr></table></figure><p>本函数<strong>编译模型以供训练</strong>，参数有：</p><ul><li>optimizer：优化器，为预定义优化器名或优化器对象</li><li>loss：目标函数，为预定义损失函数名或者一个目标函数</li><li>metrics：列表， 包含评估模型在训练和测试时的性能指标，典型用法是<code>metrics=['accuracy']</code>。如果要在多输出模型中为不同的输出指定不同的指标，可向该参数传递一个字典，例如<code>metrics={'output_a': 'accuracy'}</code></li><li>sample_weight_mode：如果你需要按时间步为样本赋权（2D权矩阵），将该值设为“temporal”。默认为“None”，代表按样本赋权（1D权）。如果模型有多个输出，可以向该参数传入指定sample_weight_mode的字典或列表。在下面<code>fit</code>函数的解释中有相关的参考内容。</li><li>kwargs：使用TensorFlow作为后端请忽略该参数，若使用Theano作为后端，kwargs的值将会传递给 K.function</li></ul><h3 id="fit"><a class="markdownIt-Anchor" href="#fit"></a> fit</h3><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">fit(self, x, y, <span class="attribute">batch_size</span>=32, <span class="attribute">np_epoch</span>=10, <span class="attribute">verbose</span>=1, callbacks=[], <span class="attribute">validation_split</span>=0.0, <span class="attribute">validation_data</span>=None, <span class="attribute">shuffle</span>=<span class="literal">True</span>, <span class="attribute">class_weight</span>=None, <span class="attribute">sample_weight</span>=None)</span><br></pre></td></tr></table></figure><p>本函数<strong>用以训练模型</strong>，参数有：</p><ul><li>x：输入数据。如果模型只有一个输入，那么x的类型是numpy array，如果模型有多个输入，那么x的类型应当为list，list的元素是对应于各个输入的numpy array。</li><li>y：标签， numpy array。如果模型有多个输出，可以传入一个numpy array的list。如果模型的输出拥有名字，则可以传入一个字典，将输出名与其标签对应起来。</li><li>batch_size：整数，指定进行梯度下降时每个batch包含的样本数。训练时一个batch的样本会被计算一次梯度下降，使目标函数优化一步。</li><li>np_epoch：整数，训练的轮数，训练数据将会被遍历nb_epoch次。Keras中nb开头的变量均为&quot;number of&quot;的意思。</li><li>verbose：日志显示，0为不在标准输出流输出日志信息，1为输出进度条记录，2为每个epoch输出一行记录。</li><li>callbacks：list，其中的元素是<code>keras.callbacks.Callback</code>的对象。这个list中的回调函数将会在训练过程中的适当时机被调用。</li><li>validation_split：0~1之间的浮点数，用来<strong>指定训练集的一定比例数据作为验证集</strong>。验证集将不参与训练，并在每个epoch结束后测试的模型的指标，如损失函数、精确度等。</li><li>validation_data：形式为（X，y）或（X，y，sample_weights）的tuple，是指定的验证集。此参数将覆盖validation_spilt。</li><li>class_weight：字典，将不同的类别映射为不同的权值，该参数用来在训练过程中调整损失函数（只能用于训练）。该参数在处理非平衡的训练数据（某些类的训练样本数很少）时，可以使得损失函数对样本数不足的数据更加关注。</li><li>sample_weight：权值的numpy array，用于在训练时调整损失函数（仅用于训练）。可以传递一个1D的与样本等长的向量用于对样本进行1对1的加权，或者在面对时序数据时，传递一个的形式为（samples，sequence_length）的矩阵来为每个时间步上的样本赋不同的权。这种情况下请确定在编译模型时添加了<code>sample_weight_mode='temporal'</code>。</li></ul><p><code>fit</code>函数返回一个<code>History</code>对象，其<code>History.history</code>属性，记录了损失函数和其他指标的数值随epoch变化的情况，如果有验证集的话，也包含了验证集的这些指标的变化情况。</p><h3 id="evaluate"><a class="markdownIt-Anchor" href="#evaluate"></a> evaluate</h3><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">evaluate(self, x, y, <span class="attribute">batch_size</span>=32, <span class="attribute">verbose</span>=1, <span class="attribute">sample_weight</span>=None)</span><br></pre></td></tr></table></figure><p>本函数按batch计算<strong>在某些输入数据上模型的误差</strong>，其参数有：</p><ul><li>x：输入数据，与<code>fit</code>一样，是numpy array或numpy array的list。</li><li>y：标签，numpy array。</li><li>batch_size：整数，含义同<code>fit</code>的同名参数。</li><li>verbose：含义同<code>fit</code>的同名参数，但只能取0或1。</li><li>sample_weight：numpy array，含义同<code>fit</code>的同名参数。</li></ul><p>本函数返回一个测试误差的标量值（如果模型没有其他评价指标），或一个标量的list（如果模型还有其他的评价指标）。<code>model.metrics_names</code>将给出list中各个值的含义。</p><h3 id="predict"><a class="markdownIt-Anchor" href="#predict"></a> predict</h3><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">predict(self, x, <span class="attribute">batch_size</span>=32, <span class="attribute">verbose</span>=0)</span><br></pre></td></tr></table></figure><p>本函数按batch获得<strong>输入数据对应的输出</strong>，其参数有：</p><p>函数的返回值是预测值的numpy array</p><h3 id="fit_generator"><a class="markdownIt-Anchor" href="#fit_generator"></a> fit_generator</h3><figure class="highlight reasonml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">fit<span class="constructor">_generator(<span class="params">self</span>, <span class="params">generator</span>, <span class="params">sample_per_epoch</span>, <span class="params">nb_epoch</span>, <span class="params">verbose</span>=1, <span class="params">callbacks</span>=[], <span class="params">validation_data</span>=None, <span class="params">nb_val_samples</span>=None, <span class="params">class_weight</span>=&#123;&#125;, <span class="params">max_q_size</span>=10)</span></span><br></pre></td></tr></table></figure><p>利用Python的生成器，<strong>逐个生成数据的batch并进行训练</strong>。生成器与模型将并行执行以提高效率。</p><p>函数的参数是：</p><ul><li>generator：生成器函数，生成器的输出应该为：<ul><li>一个形如（inputs，targets）的tuple</li><li>一个形如（inputs, targets,sample_weight）的tuple。所有的返回值都应该包含相同数目的样本。生成器将无限在数据集上循环。每个epoch以经过模型的样本数达到<code>samples_per_epoch</code>时，记一个epoch结束</li></ul></li><li>samples_per_epoch：整数，当模型处理的样本达到此数目时计一个epoch结束，执行下一个epoch</li><li>verbose：日志显示，0为不在标准输出流输出日志信息，1为输出进度条记录，2为每个epoch输出一行记录</li><li>validation_data：具有以下三种形式之一<ul><li>生成验证集的生成器</li><li>一个形如（inputs,targets）的tuple</li><li>一个形如（inputs,targets，sample_weights）的tuple</li></ul></li><li>nb_val_samples：仅当<code>validation_data</code>是生成器时使用，用以限制在每个epoch结束时用来验证模型的验证集样本数，功能类似于<code>samples_per_epoch</code></li><li>max_q_size：生成器队列的最大容量</li></ul><p>函数返回一个<code>History</code>对象。</p><p>一个简单的例子。</p><figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">def generate_arrays_from_file(<span class="type">path</span>):</span><br><span class="line">    <span class="keyword">while</span> <span class="number">1</span>:</span><br><span class="line">    f = <span class="keyword">open</span>(<span class="type">path</span>)</span><br><span class="line">    <span class="keyword">for</span> <span class="type">line</span> <span class="keyword">in</span> f：</span><br><span class="line">        # <span class="keyword">create</span> numpy <span class="keyword">array</span> <span class="keyword">of</span> <span class="keyword">input</span> data</span><br><span class="line">        # <span class="keyword">and</span> labels, <span class="keyword">from</span> <span class="keyword">each</span> <span class="type">line</span> <span class="keyword">in</span> the file</span><br><span class="line">        x, y = process_line(<span class="type">line</span>)</span><br><span class="line">        yield(x, y)</span><br><span class="line">     f.<span class="keyword">close</span>()</span><br><span class="line">     </span><br><span class="line">model.fit_generator(generate_arrays_from_file(<span class="string">'/my_file.txt'</span>),samples_per_epoch=<span class="number">10000</span>, nb_epoch=<span class="number">10</span>)</span><br></pre></td></tr></table></figure><h3 id="evaluate_generator"><a class="markdownIt-Anchor" href="#evaluate_generator"></a> evaluate_generator</h3><figure class="highlight reasonml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">evaluate<span class="constructor">_generator(<span class="params">self</span>, <span class="params">generator</span>, <span class="params">val_samples</span>, <span class="params">max_q_size</span>=10)</span></span><br></pre></td></tr></table></figure><p>本函数使用一个生成器作为数据源，来评估模型，生成器应返回与<code>test_on_batch</code>的输入数据相同类型的数据。</p><p>函数的参数是：</p><ul><li>generator：生成输入batch数据的生成器</li><li>val_samples：生成器应该返回的总样本数</li><li>max_q_size：生成器队列的最大容量</li><li>nb_worker：使用基于进程的多线程处理时的进程数</li><li>pickle_safe：若设置为True，则使用基于进程的线程。注意因为它的实现依赖于多进程处理，不可传递不可pickle的参数到生成器中，因为它们不能轻易的传递到子进程中。</li></ul><h3 id="predict_generator"><a class="markdownIt-Anchor" href="#predict_generator"></a> predict_generator</h3><figure class="highlight reasonml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">predict<span class="constructor">_generator(<span class="params">self</span>, <span class="params">generator</span>, <span class="params">val_samples</span>, <span class="params">max_q_size</span>=10, <span class="params">nb_worker</span>=1, <span class="params">pickle_safe</span>=False)</span></span><br></pre></td></tr></table></figure><p>从一个生成器上获取数据并进行预测，生成器应返回与<code>predict_on_batch</code>输入类似的数据。</p><p>函数的参数是：</p><ul><li>generator：生成输入batch数据的生成器</li><li>val_samples：生成器应该返回的总样本数</li><li>max_q_size：生成器队列的最大容量</li><li>nb_worker：使用基于进程的多线程处理时的进程数</li><li>pickle_safe：若设置为True，则使用基于进程的线程。注意因为它的实现依赖于多进程处理，不可传递不可pickle的参数到生成器中，因为它们不能轻易的传递到子进程中。</li></ul><hr />]]></content>
      
      
      <categories>
          
          <category> 深度学习小技巧 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Keras </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Image hashing with OpenCV and Python</title>
      <link href="/2020/04/22/Image-hashing-with-OpenCV-and-Python/"/>
      <url>/2020/04/22/Image-hashing-with-OpenCV-and-Python/</url>
      
        <content type="html"><![CDATA[<blockquote><p>写在前面：这篇文章摘自<strong>Adrian Rosebrock</strong>的一篇技术博客，这里只做简单的翻译总结。如果想直接看原文的话，可以点击以下链接查看：<a href="https://www.pyimagesearch.com/2017/11/27/image-hashing-opencv-python/" target="_blank" rel="noopener">Image hashing with OpenCV and Python</a></p></blockquote><p><img src="https://ftp.bmp.ovh/imgs/2020/04/9f118c121b0f31be.png" alt="" /></p><p>Image hashing 或者 perceptual hashing 的过程包括：</p><ol><li>检测一张图像的内容</li><li>根据输入图像的内容，为它创建一个特殊的hash值</li></ol><p>或许最出名的Image hashing 工具/服务是<a href="https://tineye.com/" target="_blank" rel="noopener">TinEye</a>，它是一个逆向的图像搜索引擎。</p><p>使用TinEye, 用户可以：</p><ol><li>上传一张图片</li><li>TinEye会告诉用户网上这张图片的出处</li></ol><p>在这节的开头，你可以看到一个可视化的perceptual hashing/image hashing的例子。</p><p>对于一张给定的输入图像，我们的算法会根据图像的视觉表现来计算图片的hash值。同时外观<strong>相似</strong>的图像，也应该有尽可能相似的hash值。（这里相似是指hash值之间的Hamming距离）</p><p>通过使用image hashing 算法，我们可以在一定的时间内找到近似的图像。其中最差的情况是，我们需要遍历整个数据结构，时间复杂度是O(lg n)。</p><p>这里做个提醒，通过这篇文章我们会：</p><ol><li>讨论image hashing/perceptual hashing(和为什么传统的hash不奏效)</li><li>实现image hashing， 特别是difference hashing(dHash)</li><li>使用image hashing来解决现实世界中的问题</li></ol><h3 id="step-1-将输入图像转化为灰度图"><a class="markdownIt-Anchor" href="#step-1-将输入图像转化为灰度图"></a> <strong>Step #1: 将输入图像转化为灰度图</strong></h3><p>我们image hashing算法的第一步是将输入的图像转化为灰度图，同时舍弃所有的颜色信息。</p><p>舍弃颜色信息可以让我们：</p><ol><li>对图像进行hash的过程变得更快，因为我们只需要检测一个通道</li><li>匹配那些相同但是颜色空间稍有出入的图像（因为颜色信息已经被我们去除了）</li></ol><p>如果无论如何你都对颜色特别感兴趣，你可以将image hashing 算法分别运用在每个通道上，然后最后将结果结合起来。（尽管这会导致三倍大的hash)</p><h3 id="step-2-修改原始图像的大小"><a class="markdownIt-Anchor" href="#step-2-修改原始图像的大小"></a> Step #2: 修改原始图像的大小</h3><p>由于我们的输入图像已经被转换成灰度图了，我们需要忽略横纵比，将它压缩到9×8的像素。对于大多数的图像和数据集来说，修改原始图片大小的步骤是这个算法最慢的一步。</p><p>然而，现在的你可能有两个问题：</p><ol><li>我们在修改原始图像大小的时候为什么要忽略横纵比？</li><li>为什么是9×8的像素——这似乎是一个很奇怪的大小？</li></ol><p>首先回答第一个问题：</p><p>我们将图像压缩到9×8的大小同时忽略横纵比，是为了确保image hash的结果可以匹配相似的图像而不管它们初始的空间维度。</p><p>第二个问题需要更多的解释，我们会在下一步进行解答。</p><h3 id="step-3-计算图片之间的差异"><a class="markdownIt-Anchor" href="#step-3-计算图片之间的差异"></a> Step #3: 计算图片之间的差异</h3><p>我们最后的目标是计算一个64-bit的hash——因为8×8=64，十分接近我们目标。</p><p>因此，为什么要将图像的大小修改为9×8呢？</p><p>请牢记我们需要实现算法的名字：<strong>difference hash</strong>。Difference hash算法通过计算相邻像素的差异而生效。</p><p>如果我们使用一张每行有9个像素的图作为输入图像， 然后计算相邻列的像素，我们最后会得到8个不同结果。8行就会产生64个不同的结果，而这个结果也是我们希望编程的64位的hash.</p><p>事实上，我们并不一定要计算差异——我们可以使用更好的方法来测试。</p><p>如果你对这点仍有疑惑，不用担心， 一旦我们开始看一些代码之后，相信一切都会变得清晰起来。</p><h3 id="step-4-建立hash"><a class="markdownIt-Anchor" href="#step-4-建立hash"></a> Step #4: 建立hash</h3><p>最后一步是分配bit值按后建立结果hash。为了实现这个目标，我们使用一个简单的二分类测试。</p><p>给定一张差异图像D，设其对应的像素为P，我们使用下面的测试：<code>P[X] &gt; P[X + 1] = 1 else 0</code>。</p><p>在这个例子中，我们测试左边的像素是不是比右边的像素更亮。如果左边像素更亮的话，我们就将输出值设为1。否则，如果左边的像素更暗的话，我们就将输出值设为0.</p><p>输出的图像如下图所示。</p><p><img src="https://ftp.bmp.ovh/imgs/2020/04/95be7a7393327c8e.png" alt="" /></p><h3 id="使用difference-hash的好处"><a class="markdownIt-Anchor" href="#使用difference-hash的好处"></a> 使用Difference hash的好处</h3><p>使用difference hash 有很多好处，主要包含以下几点：</p><ol><li>如果我们输入图像的横纵比改变的话，我们的image hash也不会改变</li><li>调整亮度或者对比度：1)不会改变我们的hash值 2）或者只是有轻微改变，以确保hash值彼此尽可能贴近</li><li>Difference hash非常快</li></ol><p><em>以下是代码部分：</em></p><figure class="highlight xl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"># <span class="keyword">import</span> the necessary packages</span><br><span class="line">from imutils <span class="keyword">import</span> paths</span><br><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line"><span class="keyword">import</span> <span class="built_in">time</span></span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">import</span> os</span><br></pre></td></tr></table></figure><figure class="highlight ruby"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># define the difference hash function </span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">dhash</span><span class="params">(image, hashSize=<span class="number">8</span>)</span></span><span class="symbol">:</span></span><br><span class="line"><span class="comment"># resize the input image, adding a single column (width) so we</span></span><br><span class="line"><span class="comment"># can compute the horizontal gradient</span></span><br><span class="line">resized = cv2.resize(image, (hashSize + <span class="number">1</span>, hashSize))</span><br><span class="line"><span class="comment"># compute the (relative) horizontal gradient between adjacent</span></span><br><span class="line"><span class="comment"># column pixels</span></span><br><span class="line">diff = resized[<span class="symbol">:</span>, <span class="number">1</span><span class="symbol">:</span>] &gt; resized[<span class="symbol">:</span>, <span class="symbol">:-</span><span class="number">1</span>]</span><br><span class="line"><span class="comment"># convert the difference image to a hash</span></span><br><span class="line"><span class="keyword">return</span> sum([<span class="number">2</span> ** i <span class="keyword">for</span> (i, v) <span class="keyword">in</span> enumerate(diff.flatten()) <span class="keyword">if</span> v])</span><br></pre></td></tr></table></figure><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># construct the argument parse and parse the arguments</span></span><br><span class="line">ap = argparse.ArgumentParser()</span><br><span class="line">ap.add_argument(<span class="string">"-a"</span>, <span class="string">"--haystack"</span>, <span class="attribute">required</span>=<span class="literal">True</span>,</span><br><span class="line"><span class="attribute">help</span>=<span class="string">"dataset of images to search through (i.e., the haytack)"</span>)</span><br><span class="line">ap.add_argument(<span class="string">"-n"</span>, <span class="string">"--needles"</span>, <span class="attribute">required</span>=<span class="literal">True</span>,</span><br><span class="line"><span class="attribute">help</span>=<span class="string">"set of images we are searching for (i.e., needles)"</span>)</span><br><span class="line">args = vars(ap.parse_args())</span><br></pre></td></tr></table></figure><figure class="highlight nix"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># grab the paths to both the haystack and needle images </span></span><br><span class="line">print(<span class="string">"[INFO] computing hashes for haystack..."</span>)</span><br><span class="line"><span class="attr">haystackPaths</span> = list(paths.list_images(args[<span class="string">"haystack"</span>]))</span><br><span class="line"><span class="attr">needlePaths</span> = list(paths.list_images(args[<span class="string">"needles"</span>]))</span><br><span class="line"><span class="comment"># remove the `\` character from any filenames containing a space</span></span><br><span class="line"><span class="comment"># (assuming you're executing the code on a Unix machine)</span></span><br><span class="line"><span class="keyword">if</span> sys.platform != <span class="string">"win32"</span>:</span><br><span class="line"><span class="attr">haystackPaths</span> = [p.replace(<span class="string">"\\"</span>, <span class="string">""</span>) for p <span class="keyword">in</span> haystackPaths]</span><br><span class="line"><span class="attr">needlePaths</span> = [p.replace(<span class="string">"\\"</span>, <span class="string">""</span>) for p <span class="keyword">in</span> needlePaths]</span><br></pre></td></tr></table></figure><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># grab the base subdirectories for the needle paths, initialize the</span></span><br><span class="line"><span class="comment"># dictionary that will map the image hash to corresponding image,</span></span><br><span class="line"><span class="comment"># hashes, then start the timer</span></span><br><span class="line"><span class="attr">BASE_PATHS</span> = set([p.split(os.path.sep)[-<span class="number">2</span>] for p in needlePaths])</span><br><span class="line"><span class="attr">haystack</span> = &#123;&#125;</span><br><span class="line"><span class="attr">start</span> = time.time()</span><br></pre></td></tr></table></figure><figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># loop over the haystack paths</span></span><br><span class="line"><span class="attr">for</span> <span class="string">p in haystackPaths:</span></span><br><span class="line"><span class="comment"># load the image from disk</span></span><br><span class="line"><span class="attr">image</span> = <span class="string">cv2.imread(p)</span></span><br><span class="line"><span class="comment"># if the image is None then we could not load it from disk (so</span></span><br><span class="line"><span class="comment"># skip it)</span></span><br><span class="line"><span class="attr">if</span> <span class="string">image is None:</span></span><br><span class="line"><span class="attr">continue</span></span><br><span class="line"><span class="comment"># convert the image to grayscale and compute the hash</span></span><br><span class="line"><span class="attr">image</span> = <span class="string">cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)</span></span><br><span class="line"><span class="attr">imageHash</span> = <span class="string">dhash(image)</span></span><br><span class="line"><span class="comment"># update the haystack dictionary</span></span><br><span class="line"><span class="attr">l</span> = <span class="string">haystack.get(imageHash, [])</span></span><br><span class="line"><span class="attr">l.append(p)</span></span><br><span class="line"><span class="meta">haystack[imageHash]</span> = <span class="string">l</span></span><br></pre></td></tr></table></figure><figure class="highlight gauss"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta"># show timing for hashing haystack images, then start computing the</span></span><br><span class="line"><span class="meta"># hashes for needle images</span></span><br><span class="line"><span class="keyword">print</span>(<span class="string">"[INFO] processed &#123;&#125; images in &#123;:.2f&#125; seconds"</span>.<span class="keyword">format</span>(</span><br><span class="line"><span class="built_in">len</span>(haystack), <span class="built_in">time</span>.<span class="built_in">time</span>() - start))</span><br><span class="line"><span class="keyword">print</span>(<span class="string">"[INFO] computing hashes for needles..."</span>)</span><br></pre></td></tr></table></figure><figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># loop over the needle paths</span></span><br><span class="line"><span class="attr">for</span> <span class="string">p in needlePaths:</span></span><br><span class="line"><span class="comment"># load the image from disk</span></span><br><span class="line"><span class="attr">image</span> = <span class="string">cv2.imread(p)</span></span><br><span class="line"><span class="comment"># if the image is None then we could not load it from disk (so</span></span><br><span class="line"><span class="comment"># skip it)</span></span><br><span class="line"><span class="attr">if</span> <span class="string">image is None:</span></span><br><span class="line"><span class="attr">continue</span></span><br><span class="line"><span class="comment"># convert the image to grayscale and compute the hash</span></span><br><span class="line"><span class="attr">image</span> = <span class="string">cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)</span></span><br><span class="line"><span class="attr">imageHash</span> = <span class="string">dhash(image)</span></span><br><span class="line"><span class="comment"># grab all image paths that match the hash</span></span><br><span class="line"><span class="attr">matchedPaths</span> = <span class="string">haystack.get(imageHash, [])</span></span><br><span class="line"><span class="comment"># loop over all matched paths</span></span><br><span class="line"><span class="attr">for</span> <span class="string">matchedPath in matchedPaths:</span></span><br><span class="line"><span class="comment"># extract the subdirectory from the image path</span></span><br><span class="line"><span class="attr">b</span> = <span class="string">p.split(os.path.sep)[-2]</span></span><br><span class="line"><span class="comment"># if the subdirectory exists in the base path for the needle</span></span><br><span class="line"><span class="comment"># images, remove it</span></span><br><span class="line"><span class="attr">if</span> <span class="string">b in BASE_PATHS:</span></span><br><span class="line"><span class="attr">BASE_PATHS.remove(b)</span></span><br></pre></td></tr></table></figure><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># display directories to check</span></span><br><span class="line"><span class="builtin-name">print</span>(<span class="string">"[INFO] check the following directories..."</span>)</span><br><span class="line"><span class="comment"># loop over each subdirectory and display it</span></span><br><span class="line"><span class="keyword">for</span> b <span class="keyword">in</span> BASE_PATHS:</span><br><span class="line"><span class="builtin-name">print</span>(<span class="string">"[INFO] &#123;&#125;"</span>.format(b))</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 图像处理 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> CV </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>OOP设计7大设计原则总结</title>
      <link href="/2020/04/09/OOP%E8%AE%BE%E8%AE%A17%E5%A4%A7%E8%AE%BE%E8%AE%A1%E5%8E%9F%E5%88%99%E6%80%BB%E7%BB%93/"/>
      <url>/2020/04/09/OOP%E8%AE%BE%E8%AE%A17%E5%A4%A7%E8%AE%BE%E8%AE%A1%E5%8E%9F%E5%88%99%E6%80%BB%E7%BB%93/</url>
      
        <content type="html"><![CDATA[<p>在软件开发中，为了提高软件系统的可维护性和可复用性，增加软件的可扩展性和灵活性，程序员要尽量根据 7 条原则来开发程序，从而提高软件开发效率、节约软件开发成本和维护成本。下面将为你依次介绍这7条开发原则。</p><h2 id="一-开闭原则"><a class="markdownIt-Anchor" href="#一-开闭原则"></a> 一. 开闭原则</h2><ol><li><h3 id="定义"><a class="markdownIt-Anchor" href="#定义"></a> 定义</h3><p>软件实体应当对扩展开放，对修改关闭。当应用需求改变时，在不修改软件实体源代码或者二进制代码的前提下，可以扩展模块的功能，使其满足新的需求。</p></li><li><h3 id="作用"><a class="markdownIt-Anchor" href="#作用"></a> 作用</h3><ul><li><p>对软件测试的影响。软件遵循开闭原则的话，软件测试只需要对扩展的代码进行测试就好了，因为原来的测试代码可以正常运行。</p></li><li><p>可以提高代码的可复用性。粒度越小，被复用的可能性就越大；在面向对象的程序设计中，根据原子和抽象编程可以提高代码的可复用性。</p></li><li><p>可以提高代码的可维护性。遵循开闭原则的软件，其稳定性高和延续性强，从而易于扩展和维护。</p></li></ul></li><li><h3 id="实现方法"><a class="markdownIt-Anchor" href="#实现方法"></a> 实现方法</h3><p>可以通过“抽象约束、封装变化”来实现开闭原则。即通过接口或者抽象类为软件实体定义一个相对稳定的抽象层，从而将相同的可变因素封装在相同的具体实现类中。</p><p>因为抽象灵活性好、适应性广，只要抽象地合理，可以基本保持软件架构的稳定。而软件中容易改变的细节可以从抽象派生的实现类来进行扩展，当软件需要发生变化时，只需要根据需求重新派生一个实现类来扩展就可以了。</p></li></ol><h2 id="二里氏代换原则lsp原则"><a class="markdownIt-Anchor" href="#二里氏代换原则lsp原则"></a> 二.里氏代换原则（LSP原则）</h2><ol><li><h3 id="定义-2"><a class="markdownIt-Anchor" href="#定义-2"></a> 定义</h3><p>继承必须确保超类所拥有的性质在子类中仍然成立。它是继承复用的基础，也反映了基类与子类之间的关系，是对开闭原则的补充，是对实现抽象化的具体步骤的规范。</p></li><li><h3 id="作用-2"><a class="markdownIt-Anchor" href="#作用-2"></a> 作用</h3><ul><li>里氏替换原则是实现开闭原则的重要方式之一。</li><li>它克服了继承中重写父类造成的可复用性变差的缺点。</li><li>它是动作正确性的保证。即类的扩展不会给已有的系统引入新的错误，降低了代码出错的可能性。</li></ul></li><li><h3 id="实现方法-2"><a class="markdownIt-Anchor" href="#实现方法-2"></a> 实现方法</h3><p>里氏替换原则通俗来说就是：**子类可以扩展父类的功能，但是不能改变父类原有的功能。**子类继承父类时，除了添加新的方法完成新增的功能外，尽量不要重写父类的方法。</p><p>如果通过重写父类的方法来完成新的功能，这样写起来虽然简单，但是整个继承体系的复用性会变差，特别是运行多态比较频繁时，程序运行出错的概率会非常大。</p><p>如果程序违背了里氏替换原则，继承类的对象在基类出现的地方那个会出现运行错误。<strong>修正方法是：取消原来的继承关系，重新设计它们之间的关系。</strong></p></li></ol><h2 id="三-依赖倒置原则"><a class="markdownIt-Anchor" href="#三-依赖倒置原则"></a> 三. 依赖倒置原则</h2><ol><li><h3 id="定义-3"><a class="markdownIt-Anchor" href="#定义-3"></a> 定义</h3><p>高层模块不应该依赖低层模块，两者都应该依赖其抽象；抽象不应该依赖细节，细节应该依赖抽象。</p><p><strong>核心思想：要面向接口编程，不要面向实现编程。</strong></p><p>依赖倒置原则是实现开闭原则的重要途径之一，它降低了客户与实现模块之间的耦合。而使用接口或者抽象类的目的是制定好规范和契约，而不去涉及任何具体的操作，把展现细节的任务交给它们的实现类去完成。</p></li><li><h3 id="作用-3"><a class="markdownIt-Anchor" href="#作用-3"></a> 作用</h3><ul><li>可以降低类之间的耦合性。</li><li>可以提高系统的稳定性。</li><li>可以减少并行开发引起的风险。</li><li>可以提高代码的可读性和可维护性。</li></ul></li><li><h3 id="实现方法-3"><a class="markdownIt-Anchor" href="#实现方法-3"></a> 实现方法</h3><p>我们在具体编程中只要遵循以下4点，就能在项目中满足这个规则：</p><ul><li>每个类尽量提供接口或抽象类，或者两者都具备。</li><li>变量的声明类型尽量是接口或者抽象类。</li><li>任何类都不应该从具体类派生。</li><li>使用继承时尽量遵循里氏替换原则。</li></ul></li></ol><h2 id="四-单一职责原则"><a class="markdownIt-Anchor" href="#四-单一职责原则"></a> 四. 单一职责原则</h2><ol><li><h3 id="定义-4"><a class="markdownIt-Anchor" href="#定义-4"></a> 定义</h3><p><strong>一个类应该有且仅有一个引起它变化的原因，否则类应该被拆分。</strong></p><p>该原则提出对象不应该承担太多职责，如果一个对象承担太多的职责，至少会有以下两个缺点：</p><ul><li>一个职责的变化可能会削弱或者抑制这个类实现其他职责的能力。</li><li>当客户端需要该对象的某一个职责时，不得不将其他不需要的职责全都包含进来，从而造成冗余代码或代码的浪费。</li></ul></li><li><h3 id="作用-4"><a class="markdownIt-Anchor" href="#作用-4"></a> 作用</h3><ul><li>降低类的复杂度。一个类只负责一项职责，其逻辑肯定要比负责多项职责简单得多。</li><li>提高类的可读性。复杂性降低，自然其可读性会提高。</li><li>提高系统的可维护性。可读性提高，那自然更容易维护了。</li></ul></li><li><h3 id="实现方法-4"><a class="markdownIt-Anchor" href="#实现方法-4"></a> 实现方法</h3><p>单一职责原则是最简单但又最难运用的原则，需要设计人员发现类的不同职责并将其分离，再封装到不同的类或模块中。而发现类的多重职责需要设计人员具有较强的分析设计能力和相关重构经验。</p></li></ol><h2 id="五接口隔离原则isp"><a class="markdownIt-Anchor" href="#五接口隔离原则isp"></a> 五.接口隔离原则(ISP)</h2><ol><li><h3 id="定义-5"><a class="markdownIt-Anchor" href="#定义-5"></a> 定义</h3><p>程序员应尽量将臃肿庞大的接口拆分成更小和更具体的接口，让接口只包含客户感兴趣的方法。<strong>一个类对另一个类的依赖应该建立在最小的接口之上。</strong></p></li><li><h3 id="接口隔离原则和单一职责原则的区别"><a class="markdownIt-Anchor" href="#接口隔离原则和单一职责原则的区别"></a> 接口隔离原则和单一职责原则的区别</h3><ul><li>单一职责原则注重的是职责，而接口隔离原则注重的是对接口依赖的隔离。</li><li>单一职责原则主要是约束类，它针对的是程序中的实现和细节；接口隔离原则主要是约束接口，主要针对抽象和程序整体框架的构建。</li></ul></li><li><h3 id="作用-5"><a class="markdownIt-Anchor" href="#作用-5"></a> 作用</h3><ul><li>将臃肿庞大的接口分解为多个粒度小的接口，可以预防外来变更的扩散，提高系统的灵活性和可维护性。</li><li>接口隔离提高了系统的内聚性，减少了对外交互，降低了系统的耦合性。</li><li>如果接口的粒度大小定义合理，能够保证系统的稳定性；但是，<strong>如果定义过小，则会造成接口数量过多，使设计复杂化；如果定义太大，灵活性降低，无法提供定制服务，给整体项目带来无法预料的风险。</strong></li><li>使用多个专门的接口还能够体现对象的层次，因为可以通过接口的继承，实现对总接口的定义。</li><li>能减少项目工程中的代码冗余。</li></ul></li><li><h3 id="实现方法-5"><a class="markdownIt-Anchor" href="#实现方法-5"></a> 实现方法</h3><ul><li>接口尽量小，但是要有限度。一个接口只服务于一个子模块或业务逻辑。</li><li>为依赖接口的类定制服务。只提供调用者需要的方法，屏蔽不需要的方法。</li><li>了解环境，拒绝盲从。每个项目或产品都有选定的环境因素，环境不同，接口拆分的标准就不同深入了解业务逻辑。</li><li>提高内聚，减少对外交互。使接口用最少的方法去完成最多的事情。</li></ul></li></ol><h2 id="六迪米特法则"><a class="markdownIt-Anchor" href="#六迪米特法则"></a> 六.迪米特法则</h2><ol><li><h3 id="定义-6"><a class="markdownIt-Anchor" href="#定义-6"></a> 定义</h3><p><strong>只与你“直接朋友”交谈，不跟“陌生人”说话。</strong></p><p>迪米特法则中的“朋友”是指：当前对象本身、当前对象的成员对象、当前对象所创建的对象、当前对象的方法参数等，这些对象同当前对象存在关联、聚合或组合关系，可以直接访问这些对象的方法。</p><p>如果两个软件实体无需直接通信，那么就不应当发生直接的相互调用，可以通过第三方转发该调用。其目的是降低类之间的耦合度，提高模块的相对独立性。</p></li><li><h3 id="作用-6"><a class="markdownIt-Anchor" href="#作用-6"></a> 作用</h3><ul><li><p>降低了类之间的耦合度，提高了模块的相对独立性。</p></li><li><p>由于亲合度降低，从而提高了类的可复用率和系统的扩展性。</p></li></ul><p><em>注：过度使用迪米特法则会使系统产生大量的中介类，从而增加系统的复杂性，使模块之间的通信效率降低。</em></p></li><li><h3 id="实现方法-6"><a class="markdownIt-Anchor" href="#实现方法-6"></a> 实现方法</h3><ul><li><p>从依赖者的角度来说，只依赖应该依赖的对象。</p></li><li><p>从被依赖者的角度说，只暴露应该暴露的方法。</p></li></ul></li><li><h3 id="使用迪米特法则应注意的点"><a class="markdownIt-Anchor" href="#使用迪米特法则应注意的点"></a> 使用迪米特法则应注意的点</h3><ul><li><p>在类的划分上，应该创建弱耦合的类。类与类之间的耦合越弱，就越有利于实现可复用的目标。</p></li><li><p>在类的结构设计上，尽量降低类成员的访问权限。</p></li><li><p>在类的设计上，优先考虑将一个类设置成不变类。</p></li><li><p>在对其他类的引用上，将引用其他对象的次数降到最低。</p></li><li><p>不暴露类的属性成员，而应该提供相应的访问器（set 和 get 方法）。</p></li><li><p>谨慎使用序列化（Serializable）功能。</p></li></ul></li></ol><h2 id="七合成复用原则crp"><a class="markdownIt-Anchor" href="#七合成复用原则crp"></a> 七.合成复用原则(CRP)</h2><ol><li><h3 id="定义-7"><a class="markdownIt-Anchor" href="#定义-7"></a> 定义</h3><p>在软件复用时，要尽量先使用组合或者聚合等关联关系来实现，其次才考虑使用继承关系来实现。<strong>如果要使用继承关系，必须得严格遵循里氏替换原则。</strong></p></li><li><h3 id="作用及重要性"><a class="markdownIt-Anchor" href="#作用及重要性"></a> 作用及重要性</h3><p>通常类的复用分为继承复用和合成复用两种。继承复用虽然简单易实现，但是它也有很多缺点：</p><ul><li><p>继承复用破坏了类的封装性。因为继承会将父类的实现细节暴露给子类，父类对子类是透明的，所以这种复用又称为“白箱”复用。</p></li><li><p>子类与父类的耦合度高。父类的实现的任何改变都会导致子类的实现发生变化，这不利于类的扩展与维护。</p></li><li><p>它限制了复用的灵活性。从父类继承而来的实现是静态的，在编译时已经定义，所以在运行时不可能发生变化。</p></li></ul><p>采用组合或者聚合复用时，则可避免这些缺点，同时也具备以下优点：</p><ul><li>维持了类的封装性。因为成分对象的内部细节是新对象看不见的，所以这种复用又称为“黑箱”复用。</li><li>新旧类之间的耦合度低。这种复用所需的依赖较少，新对象存取成分对象的唯一方法是通过成分对象的接口。</li><li>复用的灵活性高。这种复用可以在运行时动态进行，新对象可以动态地引用与成分对象类型相同的对象。</li></ul><h3 id="3实现方法"><a class="markdownIt-Anchor" href="#3实现方法"></a> 3.实现方法</h3><p>通过将已有的对象纳入新对象中，作为新对象的成员对象来实现的，新对象可以调用已有对象的功能，从而达到复用。</p></li></ol><h2 id="八总结"><a class="markdownIt-Anchor" href="#八总结"></a> 八.总结</h2><p>以上介绍的7种设计原则是软件设计模式必须遵循的原则，各种原则要求的侧重点不同。</p><ul><li><p>开闭原则是总纲，它告诉我们要对扩展开放，对修改关闭。</p></li><li><p>里氏替换原则告诉我们不要破坏继承体系。</p></li><li><p>依赖倒置原则告诉我们要面向接口编程。</p></li><li><p>单一职责原则告诉我们实现类要职责单一。</p></li><li><p>接口隔离原则告诉我们在设计接口的时候要精简单一。</p></li><li><p>迪米特法则告诉我们要降低耦合度。</p></li><li><p>合成复用原则告诉我们要优先使用组合或者聚合关系复用，少用继承关系复用。</p></li></ul><hr /><p>以上内容整理自 <a href="http://c.biancheng.net/design_pattern/" target="_blank" rel="noopener">C语言中文网 </a>，感谢你的阅读。</p>]]></content>
      
      
      <categories>
          
          <category> 软件体系结构与设计模式 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 设计模式 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>针对Github下载速度过慢的解决办法</title>
      <link href="/2020/03/25/%E9%92%88%E5%AF%B9Github%E4%B8%8B%E8%BD%BD%E9%80%9F%E5%BA%A6%E8%BF%87%E6%85%A2%E7%9A%84%E8%A7%A3%E5%86%B3%E5%8A%9E%E6%B3%95/"/>
      <url>/2020/03/25/%E9%92%88%E5%AF%B9Github%E4%B8%8B%E8%BD%BD%E9%80%9F%E5%BA%A6%E8%BF%87%E6%85%A2%E7%9A%84%E8%A7%A3%E5%86%B3%E5%8A%9E%E6%B3%95/</url>
      
        <content type="html"><![CDATA[<p>对于一个程序员来说，逛Github可以说是一件必不可少的事情，毕竟这是全球最大的~~“同性交友网站”~~程序员交流网站。我们也会经常看到一些感兴趣的项目，于是便想着下载下来研究。经常困扰我们的一个问题就是，从Github上下载项目实在是太慢了，每秒十几kb的下载速度让人抓狂，实在是太太太太太慢了。于是便想着有没有什么办法可以提高下载速度，从网上搜索了一番，发现了可以借助**”码云“**间接下载Github上的项目。</p><p>接下来，我就简单介绍一下用&quot;码云&quot;下载Github项目的流程。</p><p><strong>1.注册码云</strong></p><p>首先简单介绍一下&quot;码云&quot;这个网站吧，它是码云是开源中国社区2013年推出的基于 Git 的代码托管服务，目前已经成为国内最大的代码托管平台，致力于为国内开发者提供优质稳定的托管服务。(摘自官方介绍) 简单来说，它和Github的性质是一样的，只是它的服务器在国内，访问和下载速度会相对快很多。</p><p>首先贴上”码云“官方网站的链接：<a href="https://gitee.com/" target="_blank" rel="noopener">码云</a> 。</p><p>打开网站之后，在网站右上角有&quot;注册&quot;按钮，鼠标点击进行注册。</p><p><img src="https://i.loli.net/2020/03/26/Q3gAB1O5UnI97KN.png" alt="2020-03-26_004814.png" /></p><p>注册的时候，尽量使用英文的用户姓名，并且英文名和你的个人码云的地址有关。同时在注册的时候需要验证手机或者邮箱。</p><p><img src="https://i.loli.net/2020/03/26/N4xUMRfiZKJYote.png" alt="2020-03-26_005145.png" /></p><p><strong>2.将你需要下载的仓库，导入自己的码云中</strong></p><p>用注册的账户登录之后，你会看到如下操作界面。在界面的左下角有一个“仓库”的区间，点击**&quot;+&quot;**进行仓库的添加。</p><p><img src="https://i.loli.net/2020/03/26/RcLneXVDTFU8zHk.png" alt="2020-03-26_005242.png" /></p><p>&quot;+&quot;点击完毕后，在跳出的界面往下拉，在页面底端会有一个&quot;<strong>导入已有仓库</strong>&quot;的链接，点击之后在输入框中贴上自己想要导入的库，然后点击创建。</p><p><img src="https://i.loli.net/2020/03/26/2fWRxuUDckzJgrC.png" alt="2020-03-26_005455.png" /></p><p><img src="https://s1.ax1x.com/2020/03/26/8xg2an.png" alt="8xg2an.png" /></p><p>导入数据需要花点时间，过了一段时间，系统会提示你导入成功，你会看到你导入的库。点击右上方的&quot;克隆/下载&quot;按钮，便可进行克隆和下载。</p><p>你可以下载ZIP格式的压缩文件，也可以通过复制HTTPS的文件，通过git进行下载。</p><p><img src="https://s1.ax1x.com/2020/03/26/8xgLI1.png" alt="8xgLI1.png" /></p><p>下载的速度比直接用Github下载快很多，妈妈再也不用担心下大型的项目要花很长时间了。下载速度可以达到3MB每秒，可以说速度还可以了。</p><p><img src="https://s1.ax1x.com/2020/03/26/8x28J0.png" alt="8x28J0.png" /></p><hr /><p>以上教程来自网络，这里只做记录分享，感谢您的阅读。</p>]]></content>
      
      
      <categories>
          
          <category> 杂七杂八 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 技术问题 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>高级人工智能之通过搜索解决问题</title>
      <link href="/2020/03/20/%E9%AB%98%E7%BA%A7%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E4%B9%8B%E9%80%9A%E8%BF%87%E6%90%9C%E7%B4%A2%E8%A7%A3%E5%86%B3%E9%97%AE%E9%A2%98/"/>
      <url>/2020/03/20/%E9%AB%98%E7%BA%A7%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E4%B9%8B%E9%80%9A%E8%BF%87%E6%90%9C%E7%B4%A2%E8%A7%A3%E5%86%B3%E9%97%AE%E9%A2%98/</url>
      
        <content type="html"><![CDATA[<h3 id="1人工智能中的问题求解"><a class="markdownIt-Anchor" href="#1人工智能中的问题求解"></a> 1.人工智能中的问题求解</h3><ul><li>解：是一个达到目标动作的序列。</li><li>过程：寻找该动作，称其为搜索。</li><li>问题形式化：给定一个目标，决定要考虑的动作与状态。</li><li>为何搜索：对于某些NP完和NP难问题，只能通过搜索来解决。</li><li>问题求解智能体：是一种基于目标的智能体，通过搜索来解决问题。</li></ul><h3 id="2相关术语"><a class="markdownIt-Anchor" href="#2相关术语"></a> 2.相关术语</h3><ul><li>状态空间：可以形式化地定义为——初始状态、动作和转换模型。</li><li>图：状态空间形成一个图，其中<em>节点表示状态、链接表示动作</em>。</li><li>路径：状态空间的一条路径是由一系列动作连接的一个状态序列。</li></ul><h3 id="3问题形式化的5个要素"><a class="markdownIt-Anchor" href="#3问题形式化的5个要素"></a> 3.问题形式化的5个要素</h3><ul><li>初始状态：智能体出发时的状态。</li><li>动作：描述智能体可执行的动作。</li><li>转换模型：描述每个动作在做什么。</li><li>目标测试：确定一个给定的状态是否为目标状态。</li><li>路径代价：每条路径所分配的一个数值代价。</li></ul><h3 id="4搜索算法"><a class="markdownIt-Anchor" href="#4搜索算法"></a> 4.搜索算法</h3><p><em>一种通用的搜索算法</em></p><p><img src="https://i.loli.net/2020/03/20/nmPtyisbGX1E5ez.png" alt="screenShot.png" /></p><p>该frontier(也称为open list)：一种数据结构，用于存储所有的叶节点。</p><p>在frontier上扩展结点的过程持续进行，知道找到一个解或者没有其它状态可扩展。</p><p><em>一种通用的图搜索算法</em></p><p><img src="https://i.loli.net/2020/03/20/nvUyDFlw3dBkE8S.png" alt="screenShot.png" /></p><p>该explored(也称为closed list)：一种数据结构，用于记忆每个扩展结点。</p><p>explored和frontier中的结点可以被丢弃。</p><h3 id="5无信息搜索"><a class="markdownIt-Anchor" href="#5无信息搜索"></a> 5.无信息搜索</h3><p>定义：无信息搜索也被称为盲目搜索。该术语(无信息、盲目的)意味着该搜索策略没有超过问题定义提供的状态之外的附加信息。</p><p>所有能做的就是生成后继结点，并且从区分一个目标状态或一个非目标状态。</p><p>所有的搜索策略是由节点扩展的顺序加以区分。这些搜索策略是：宽度优先、深度优先以及一致代价搜索。</p><p><strong>无信息搜索的策略评价</strong></p><p>一种无信息搜索是通过选择结点扩展的顺序来定义的。</p><p>其策略可按照如下特性来评价：</p><ul><li>完备性。是否总能找到一个存在的解。</li><li>时间复杂性：花费多长时间找到这个解。</li><li>空间复杂性。需要多少内存。</li><li>最优性：是否总能找到最优的解。</li></ul><p>时间复杂性和空间复杂性用如下术语来衡量：</p><ul><li>b–搜索树的最大分支因子。</li><li>d–最浅的深度。</li><li>m–搜索树的最大深度。</li></ul><p><strong>宽度优先搜索</strong></p><p>搜索策略：扩展<em>最浅的</em>未扩展节点。</p><p>实现方法：使用FIFO(先进先出)队列，即新的后继结点放在后面。</p><p><img src="https://i.loli.net/2020/03/20/LDsVGk2NOh7Blg8.png" alt="screenShot.png" /></p><p>宽度优先搜索不能解决指数复杂性问题，小的分支因子除外。</p><p><strong>一致代价搜索</strong></p><p>搜索策略：扩展<em>最低代价</em>的未扩展节点。</p><p>实现方法：队列，按路径代价排序，最低优先。</p><p><img src="https://i.loli.net/2020/03/20/IVfFqbysr8zOYw7.png" alt="screenShot.png" /></p><p><strong>深度优先搜索</strong></p><p>搜索策略：扩展最深未扩展节点。</p><p>实现方法：使用LIFO队列，把后继节点放在队列的前端。</p><p><strong>-深度受限搜索</strong></p><p>若状态空间无限，深度优先搜索就会发生失败，这个问题可以用一个预定的深度限制得到解决。</p><p>缺点：</p><p>如果我们选择l &lt; d,即最浅的的目标在深度限制之外，这种方法就会出现额外的不完备性。</p><p>如果我们选择l &gt; d,深度受限搜索也不是最优的。</p><p><img src="https://i.loli.net/2020/03/20/9JEPhTsofKFqe3w.png" alt="screenShot.png" /></p><p><strong>-迭代加深搜索</strong></p><p>它将深度优先和宽度优先的优势相结合，逐步增加深度限制反复运行直到找到目标。</p><p>它以深度优先搜索相同的顺序访问搜索树的节点，但先访问节点的累积顺序实际是宽度优先。</p><p><img src="https://i.loli.net/2020/03/20/2rOGMmtoCiHnjZA.png" alt="screenShot.png" /></p><p><strong>-双向搜索</strong></p><p>它同时进行两个搜索：一个是从初始状态向前搜索，而另一个则从目标向后搜索。当两者在中间相遇时停止。</p><p><img src="https://i.loli.net/2020/03/20/ZcyeQI5btVAsal7.png" alt="screenShot.png" /></p><p>该方法可以通过一种剩余距离的启发式估计来导向。</p><p>-无信息搜索树策略评价</p><p><img src="https://i.loli.net/2020/03/20/U3sif48aZdkFE5C.png" alt="screenShot.png" /></p><h3 id="6有信息搜索"><a class="markdownIt-Anchor" href="#6有信息搜索"></a> 6.有信息搜索</h3><p>有信息搜索也被称为<em>启发式搜索</em>，这类策略采用超出问题本身定义的、问题特有的知识，因此能够找到比无信息搜索更有效的解。</p><p>一般方法使用如下函数的一个或两者：</p><p>评价函数，记作f(n)，用于选择一个节点进行扩展。</p><p>启发式函数，记作h(n)，作为f的一个组成部分。</p><p><strong>-最佳优先搜索</strong></p><p>搜索策略：一个节点被选择进行扩展是基于一个评价函数，f(n)。大多数的最佳优先搜索算法还包含一个启发式函数，h(n)。</p><p>实现方法：与一致代价搜索相同。然而，最佳优先搜索使用f(n)代替g(n)来整体优先队列。</p><p>启发式函数h(n)：从节点n到目标状态的最低路径估计代价。</p><p>特例：<strong>贪婪搜索、A*搜索</strong></p><p><em>贪婪搜索</em></p><p>搜索策略：试图扩展最接近目标的节点。</p><p>评价函数：<strong>f(n) = h(n)</strong></p><p>它仅使用启发式函数对节点进行评价。</p><p><em>迭代加深A</em>搜索*</p><ul><li>它是迭代加深深度优先搜索的变种，从A*搜索算法借鉴了这一思想，即使用启发式函数来评价到目标的剩余代价。</li></ul><p>它是一种深度优先搜索算法，内存使用率低于A*算法。但是，不同于标准的迭代加深搜索，它集中于探索最有希望的节点，因此不会去搜索树任何处的同样深度。</p><p>比较：</p><ul><li>迭代加深深度优先搜索：使用<strong>搜索深度</strong>作为每次迭代的截止值。</li><li>迭代加深A*搜索：使用信息更丰富的评价函数，f(n) = g(n) + h(n)</li></ul><p>g(n)：到达该节点的代价    h(n)：该节点到目标的估计代价</p>]]></content>
      
      
      <categories>
          
          <category> 高级人工智能 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> AI </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>高级人工智能之智能Agent</title>
      <link href="/2020/03/20/%E9%AB%98%E7%BA%A7%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E4%B9%8B%E6%99%BA%E8%83%BDAgent/"/>
      <url>/2020/03/20/%E9%AB%98%E7%BA%A7%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E4%B9%8B%E6%99%BA%E8%83%BDAgent/</url>
      
        <content type="html"><![CDATA[<h3 id="1智能agent的特点"><a class="markdownIt-Anchor" href="#1智能agent的特点"></a> 1.智能Agent的特点：</h3><p>可自主操作、感知环境、持续动作、顺应变化、实现目标和最佳结果(或者最佳预期结果)。</p><p>概括地说，一个智能体可以被看作具有如下功能的任何事物：</p><ul><li>通过感受器感知外部环境，并且通过执行器作用于外部环境。</li><li>可以通过学习或者应用知识来实现其目标。</li></ul><h3 id="2理性agent"><a class="markdownIt-Anchor" href="#2理性agent"></a> 2.理性Agent</h3><p>定义：是一个有<strong>正确行为</strong>的智能体——该功能表中的每个条目都正确填写。</p><p>对于正确行为的解释：</p><ul><li>一个智能体在一个环境中依据感知生成一系列的动作。</li><li>这些动作由一系列状态而引起环境发生变化。</li><li>如果该系列变化是所期望的，则该智能体表现良好。</li></ul><p>对于理性的理解：</p><p>理性是指<strong>探索、学习和自主</strong>的。</p><p>理性的动作是<strong>指对给定的感知序列，能使期待的性能指标最大化</strong>。</p><p>理性同样依赖于四件事：</p><ul><li>定义成功标准的性能指标。</li><li>智能体对环境的先验知识。</li><li>智能体所能够完成的动作。</li><li>智能体最新的感知序列。</li></ul><h3 id="3peas"><a class="markdownIt-Anchor" href="#3peas"></a> 3.PEAS</h3><p>定义：PEAS是一种任务环境的规范，四个大写字母的缩写分别代表Performance(性能)、Environment(环境)、Actuators(动作器)和Sensors(感受器)。</p><p>不同的环境类型：</p><ul><li>完全可观测和部分可观测。一个智能体的传感器在每个时间点上可访问环境的完整状态，则该任务环境就是完全可观测的。</li><li>单智能体和多智能体。一个智能体在一个环境内自运行，则它就是一个单智能体。</li><li>确定性和随机性。环境的下一个状态完全由当前的状态和该智能体执行的动作所决定，则该环境是确定的。</li><li>阵发性和连续性。智能体的动作过程被分为原子的片段，并且每个片段的动作选择仅仅依赖于片段本身。</li><li>动态与静态。如果环境随智能体的行为而改变，则该智能体的环境是动态的；否则是静态的。</li><li>离散与连续。离散与连续的区别在于环境的状态、时间处理的方式、以及感知和智能体的动作。</li><li>已知与未知。在一个已知的环境下，所有动作的结果都是给定的。如果环境是未知的，则该智能体将需要学习如何动作，以便于做出正确的决策。</li></ul><h3 id="4智能体的结构"><a class="markdownIt-Anchor" href="#4智能体的结构"></a> 4.智能体的结构</h3><p>智能体的结构如下图所示：</p><p><img src="https://i.loli.net/2020/03/20/WxrBbPpXQoO7ZyC.png" alt="screenShot.png" /></p><p>智能体的层次：智能体通常表现为一个分层的结构，它包含许多&quot;子智能体&quot;，而子智能体处理和执行较低级的功能。智能体和子智能体构建一个完整的系统，它可以通过行为和反应来完成艰巨的任务。</p><p>表示智能体状态的三种方式：</p><ul><li>原子式：每个状态是一个黑盒子，没有内部结构。</li><li>因子式：每个状态由一组固定的属性和值组成。</li><li>结构式：每个状态包含对象，每个具有属性以及与其他对象的关系。</li></ul><img src="https://i.loli.net/2020/03/20/3APclwS9hsqF7Og.png" alt="screenShot.png" style="zoom:60%;" /><h3 id="5智能体的主要类别"><a class="markdownIt-Anchor" href="#5智能体的主要类别"></a> 5.智能体的主要类别</h3><p>下面介绍的5种类型的智能体，体现几乎所有智能系统的基本原理。</p><ul><li>简单反射智能体。</li><li>基于模型的反射智能体。</li><li>基于目标的智能体。</li><li>基于效用的智能体。</li><li>学习智能体。</li></ul><p><strong>简单反射智能体</strong></p><p>简单反射智能体<em>仅仅在当前感知的基础上动作，忽略其余的感知历史。</em></p><p>智能体功能是基于条件动作规则：if 条件 then 动作。</p><p><img src="https://i.loli.net/2020/03/20/LstIVNWlghCj9oH.png" alt="screenShot.png" /></p><p>关于简单反射智能体：</p><ul><li>仅当外部环境为完全可测时，该智能体的功能才能发挥。</li><li>某些反射智能体也可以包含关于其当前状态的信息，允许它们忽视执行器已被触发的条件。</li><li>智能体在部分可观测的环境下运行时，无限循环往往是无法避免的。</li><li>如果智能体可以随机产生其动作，有可能从无限循环中摆脱出来。</li></ul><p><strong>模型反射智能体</strong></p><p>一个基于模型的反射智能体<em>可以处理部分可观测环境。</em></p><p>其当前状态存储在智能体中，维护某种结构，它描述不可见外部环境中的一部分。</p><p><img src="https://i.loli.net/2020/03/20/eZdKvYznrPsfjq1.png" alt="screenShot.png" /></p><p>关于基于模型反射智能体：</p><ul><li>关于&quot;<em>外部环境如何运作</em>&quot;的知识被称为一个外部环境模型，由此得名&quot;基于模型的智能体&quot;。</li><li>基于模型的反射智能体将保持某种内部模型。</li><li>内部模型依赖于感知的历史，因此至少反射某些当前状态无法观测的方面。</li><li>它作为反射智能体以某种方式选择动作。</li></ul><p><u>一个基于模型的反射智能体算法。它采用一个内部模型来保持当前外部环境状态的轨迹，然后用等同于简单反射智能体的方式选择一个动作。</u></p><p><strong>基于目标智能体</strong></p><p>通过利用&quot;目标&quot;信息，基于目标的智能体进一步扩展了基于模型的智能体的功能。</p><p><img src="https://i.loli.net/2020/03/20/8DIXHL9Uswo5lrj.png" alt="screenShot.png" /></p><p>关于基于目标智能体：</p><ul><li>目标信息描述所希望的情形。</li><li>它允许智能体在多个可能性之间选择一种方式，挑选出达到目标状态的那一个。</li><li>搜索和规划是人工智能的子领域，致力于发现达到智能体目标的动作序列。</li><li>在某些情况下，基于目标的智能体似乎不太有效，但是它更为灵活，因为这种支持其决策的知识明显地展示出来，并且可以被修改。</li></ul><p><strong>基于效用的智能体</strong></p><p>一个特殊的状态可通过一个效用函数得到，该函数将一个状态隐射到该状态效用的度量。</p><p><img src="https://i.loli.net/2020/03/20/zul2oYN4Vq8n3T5.png" alt="screenShot.png" /></p><p>关于基于效用的智能体：</p><ul><li>一种更通用的性能度量，应该根据它们使得智能体多么&quot;高兴&quot;的程度，允许对不同的外部环境状态进行比较。</li><li>效用这个术语，可用于描述智能体是多么高兴。</li><li>一个理性的基于效用的智能体选择动作，将动作的期待效应最大化。</li><li>一个基于效用的智能体需要建模并记录环境、任务轨迹，这涉及大量的感知、表征、推理和学习的研究。</li></ul><p><strong>学习智能体</strong></p><p>学习允许智能体最初在未知的环境中运行，并且与其最初的知识相比，会变得越来越胜任。</p><p><img src="https://i.loli.net/2020/03/20/DYR8fACb1ZoKWse.png" alt="screenShot.png" /></p><p>关于学习智能体：</p><ul><li>学习要素：它利用评论者对智能体如何动作的反馈，然后决定应该如何修改性能要素以便于未来做的更好。</li><li>性能要素：获得感知并决定动作。</li><li>问题发生器：它对推荐的动作负责，这将形成新的经验。</li></ul><p><strong>智能体的分类法</strong></p><p><img src="https://i.loli.net/2020/03/20/iSeGtZwCKV6MER4.png" alt="screenShot.png" /></p>]]></content>
      
      
      <categories>
          
          <category> 高级人工智能 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> AI </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>创建型设计模式</title>
      <link href="/2020/03/16/%E5%88%9B%E5%BB%BA%E5%9E%8B%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"/>
      <url>/2020/03/16/%E5%88%9B%E5%BB%BA%E5%9E%8B%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/</url>
      
        <content type="html"><![CDATA[<h2 id="一-创建型模式的特点与分类"><a class="markdownIt-Anchor" href="#一-创建型模式的特点与分类"></a> 一. 创建型模式的特点与分类</h2><p>创建型模式的主要关注点是“怎么创建对象”，它的主要特点是“<strong>将对象的创建与使用分离</strong>”。这样可以降低系统的耦合度，使用者不需要关注对象的创建细节，对象的创建由相关的工厂来完成。</p><p>创建型模式主要分为以下几种。</p><ul><li>单例模式：某个类只生成一个实例，该类提供一个全局访问点供外部获取该实例，其拓展是有限多例模式。</li><li>原型模式：将一个对象作为原型，通过对其进行复制而克隆出多个和原型类似的新实例。</li><li>工厂方法模式：定义一个用于创建产品的接口，由子类决定生产什么产品。</li><li>抽象工厂模式：提供一个创建产品族的接口，其每个子类可以产生一系列相关的产品。</li><li>建造者模式：将一个复杂的对象分解成多个相对简单的部分，然后根据不同的需要分别创建它们，最后构建该复杂对象。</li></ul><p>以上 5 种创建型模式，除了工厂方法模式属于类创建型模式，其他的全部属于对象创建型模式。</p><h2 id="二单例模式"><a class="markdownIt-Anchor" href="#二单例模式"></a> 二.单例模式</h2><h3 id="1单例模式的定义与特点"><a class="markdownIt-Anchor" href="#1单例模式的定义与特点"></a> 1.单例模式的定义与特点</h3><p>定义：指一个类只有一个实例，且该类能自行创建这个实例的一种模式。</p><p>单例模式有3个特点：</p><ul><li>单例类只有一个实例对象。</li><li>该单例对象必须由单例类自行创建。</li><li>单例类对外提供一个访问该单例的全局访问点。</li></ul><h3 id="2单例模式的结构与应用场景"><a class="markdownIt-Anchor" href="#2单例模式的结构与应用场景"></a> 2.单例模式的结构与应用场景</h3><p>单例模式的主要角色如下：</p><ul><li>单例类：包含一个实例且能自行创建这个实例的类。</li><li>访问类：使用单例的类</li></ul><p>应用场景：</p><ul><li>某类只要求生成一个对象的时候。</li><li>当对象需要被共享的场合。由于单例模式只允许创建一个对象，共享该对象可以节省内存，并加快对象访问速度。</li><li>当某类需要频繁实例化，而创建的对象又频繁被销毁的时候。</li></ul><h2 id="三原型模式"><a class="markdownIt-Anchor" href="#三原型模式"></a> 三.原型模式</h2><h3 id="1原型模式的定义与特点"><a class="markdownIt-Anchor" href="#1原型模式的定义与特点"></a> 1.原型模式的定义与特点</h3><p>定义：用一个已经创建的实例作为原型，通过复制该原型对象来创建一个和原型相同或者相似的新对象。</p><p>特点：在这里，原型实例指定了要创建的对象的种类。用这种方法创建对象非常高效，根本不需要知道创建的细节。</p><h3 id="2原型模式的结构与应用场景"><a class="markdownIt-Anchor" href="#2原型模式的结构与应用场景"></a> 2.原型模式的结构与应用场景</h3><p>原型模式的主要角色如下：</p><ul><li>抽象原型类：规定具体原型对象必须实现的接口。</li><li>具体原型类：实现抽象原型类的clone()方法，它是可被复制的对象。</li><li>访问类：使用具体原型类中的clone()方法来复制新的对象。</li></ul><p>应用场景：</p><ul><li>对象之间相同或者相似，即只是个别的几个属性不同的时候。</li><li>对象的创建过程比较麻烦，但复制比较简单的时候。</li></ul><h2 id="四工厂方法模式"><a class="markdownIt-Anchor" href="#四工厂方法模式"></a> 四.工厂方法模式</h2><h3 id="1工厂方法模式的定义与特点"><a class="markdownIt-Anchor" href="#1工厂方法模式的定义与特点"></a> 1.工厂方法模式的定义与特点</h3><p>定义：定义一个创建产品对象的工厂接口，将产品对象实际创建工作推迟到具体子工厂类当中。满足创建型模式中要求“创建与使用相分离“的特点。</p><p>我们把创建的对象称为”产品“，把创建产品的对象称为”工厂“。如果要创建的产品不多，只需要一个工厂类就可以完成，这种模式叫”简单工厂模式“，它的缺点是增加新产品时会违背”开闭原则“。</p><p>工厂方法模式的主要优点：</p><ul><li><p>用户只需要知道具体工厂的名称就可得到所要的产品，而不需要知道产品的具体创建过程。</p></li><li><p>在系统增加新的产品时，只需要添加具体产品类和对应的具体工厂类，无须对原工厂进行任何修改，满足开闭原则。</p></li></ul><p>缺点：</p><ul><li>每增加一个产品就要增加一个具体的产品类和一个对应的具体工厂类，增加了系统的复杂度。</li></ul><h3 id="2工厂方法模式的结构与应用场景"><a class="markdownIt-Anchor" href="#2工厂方法模式的结构与应用场景"></a> 2.工厂方法模式的结构与应用场景</h3><p>工厂方法模式的主要角色如下：</p><ul><li>抽象工厂：提供了创建产品的接口，调用者通过它访问具体工厂的工厂方法来创建产品。</li><li>具体工厂：主要是实现抽象工厂中的抽象方法，完成具体产品的创建。</li><li>抽象产品：定义了产品的规范，描述了产品的主要特性和功能。</li><li>具体产品：定义抽象产品角色所定义的接口，由具体工厂来创建，它同具体工厂之间一一对应。</li></ul><p>应用场景：</p><ul><li>客户只知道创建产品的工厂名，而不知道具体的产品名。</li><li>创建对象的任务由多个具体子工厂的某一个完成，而抽象工厂只提供创建产品的接口。</li><li>客户不关系创建产品的细节，只关心产品的品牌。</li></ul><h2 id="五抽象工厂模式"><a class="markdownIt-Anchor" href="#五抽象工厂模式"></a> 五.抽象工厂模式</h2><h3 id="1抽象工厂模式的定义与特点"><a class="markdownIt-Anchor" href="#1抽象工厂模式的定义与特点"></a> 1.抽象工厂模式的定义与特点</h3><p>定义：是一种为访问类提供一个创建一组相关或相互依赖对象的接口，且访问类不需要指定所要产品的具体类就能得到同族的不同等级的产品的模式结构。</p><p>抽象工厂模式是工厂方法模式的升级版，工厂方法模式只生产一个等级的产品，而抽象工厂模式可生产多个等级的产品。</p><p>使用抽象工厂模式一般要满足以下条件：</p><ul><li>系统中有多个产品族，每个具体工厂创建同一族但属于不同等级结构的产品。</li><li>系统一次只可能消费其中某一族的产品，即同族的产品一起使用。</li></ul><p>抽象工厂模式的主要优点：</p><ul><li>可以在类的内部对产品族中相关联的多等级产品共同管理，而不必专门引入多个新的类来进行管理。</li><li>当增加一个新的产品族时不需要修改源代码，满足开闭原则。</li></ul><p>缺点：</p><ul><li>当产品族中需要增加一个新产品时，所有的工厂类都需要进行修改。</li></ul><h3 id="2抽象工厂模式的结构与应用场景"><a class="markdownIt-Anchor" href="#2抽象工厂模式的结构与应用场景"></a> 2.抽象工厂模式的结构与应用场景</h3><p>抽象工厂模式的主要角色如下：</p><ul><li><p>抽象工厂：提供了创建产品的接口，它包含多个创建产品的方法 ，可以创建多个不同等级的产品。</p></li><li><p>具体工厂：主要是实现抽象工厂中的多个抽象方法，完成具体产品的创建。</p></li><li><p>抽象产品：定义了产品的规范，描述了产品的主要特性和功能，抽象工厂模式有多个抽象产品。</p></li><li><p>具体产品：实现了抽象产品角色所定义的接口，由具体工厂来创建，它同具体工厂之间是多对一的关系。</p></li></ul><p>应用场景：</p><ul><li><p>当需要创建的对象是一系列相互关联或相互依赖的产品族时。</p></li><li><p>系统中有多个产品族，但每次只使用其中的某一族产品。</p></li><li><p>系统中提供了产品的类库，且所有产品的接口相同，客户端不依赖产品实例的创建细节和内部结构。</p></li></ul><h2 id="六建造者模式"><a class="markdownIt-Anchor" href="#六建造者模式"></a> 六.建造者模式</h2><h3 id="1建造者模式的定义与特点"><a class="markdownIt-Anchor" href="#1建造者模式的定义与特点"></a> 1.建造者模式的定义与特点</h3><p>定义：指将一个复杂对象的构造与它的表示分离，使同样的构建过程可以创建不同的表示，这样的设计模式被称为”建造者模式“。它将一个复杂的对象分解为多个简单的对象，然后一步步构建而成，它将变与不变相分离，即产品的组成部分是不变的，但每一部分是可以灵活选择的。</p><p>建造者模式的主要优点：</p><ul><li>各个具体的建造者相互独立，有利于系统的扩展。</li><li>客户端不必知道产品内部组成的细节，便于控制细节风险。</li></ul><p>缺点：</p><ul><li>产品的组成部分必须相同，这限制了其使用范围。</li><li>如果产品的内部变化复杂，该模式会增加很多建造者类。</li></ul><p>建造者模式和工厂模式的关注点不同：建造者模式注重零部件的组装过程，而工厂模式更注重零部件的创建过程，但两者可以结合使用。</p><h3 id="2建造者模式的结构与应用场景"><a class="markdownIt-Anchor" href="#2建造者模式的结构与应用场景"></a> 2.建造者模式的结构与应用场景</h3><p>建造者模式的主要角色如下：</p><ul><li><p>产品角色：它是包含多个组成部件的复杂对象，由具体建造者来创建其各个滅部件。</p></li><li><p>抽象建造者：它是一个包含创建产品各个子部件的抽象方法的接口，通常还包含一个返回复杂产品的方法 。</p></li><li><p>具体建造者：实现 Builder 接口，完成复杂产品的各个部件的具体创建方法。</p></li><li><p>指挥者：它调用建造者对象中的部件构造与装配方法完成复杂对象的创建，在指挥者中不涉及具体产品的信息。</p></li></ul><p>应用场景：</p><ul><li><p>创建的对象较复杂，由多个部件构成，各个部件面临着复杂的变化，但构件间的建造顺序是稳定。</p></li><li><p>创建复杂对象的算法独立于该对象的组成部分以及它们的装配方式，即产品的构建过程和最终的表示是独立的。</p></li></ul><hr /><p>以上是对5种创建型模式的简单介绍，文章整理自<a href="http://c.biancheng.net/view/1335.html" target="_blank" rel="noopener">C语言中心网</a> ,感谢您的阅读。</p>]]></content>
      
      
      <categories>
          
          <category> 软件体系结构与设计模式 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 设计模式 面向对象编程 </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
